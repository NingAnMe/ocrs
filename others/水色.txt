# MERSI L1 文件数据重写


# SV 提取(OBC文件)
1: 250m 的前 4 个通道，先把 SV 8000*24 使用 40 个探元转换为 200 * 24 (选择 40 个探元中某个探元号的数据)，每个通道，可配置参数取某一个探元号
2: 1000m 的 15 个通道，先把 SV 2000*6 使用 10 个探元 变为 200 * 6 (选择 10 个探元中某个探元号的数据)，每个通道，可配置参数取某一个探元号
3: 然后按照 10 行滑动 从 200 * 6 变成 200 * 1
4: 然后 10 行用 1 个 SV 均值，从 200 * 1 变成 2000 * 1
5: 总共 19 * 2000 (sv_2000)


# EV 数据计算
2013年之前
1: dn_new = dn_ev * slope_ev + intercept_ev  【# 使用原文件 dn_ev 计算新的 dn_new】
4: slope = dsl ** 2 * k2 + dsl * k1 + k0  【# k0, k1, k2 是新的】
5: arof = ((dn_new - sv_2000) * slope) * 100  【# 四舍五入取整】

2013年之后
1: dn_new = dn_ev * slope_ev + intercept_ev  【# 使用原文件 dn_ev 计算新的 dn_new】
2: slope_old = dsl**2 * k2_old + dsl * k1_old + k0_old  【# k0, k1, k2 是原文件 RSB_Cal_Cor_Coeff 储存的】
3: dn_new = dn_new / slope_old + dn_sv
4: slope_new = dsl**2 * k2_new + dsl * k1_new + k0_new  【# k0, k1, k2 是新给的】
5: arof = ((dn_new - sv_2000) * slope_new) * 100 【# 四舍五入取整】


# 数据输出(HDF5 文件，文件名与原来相同)
1： 属性
- dsl  【# dsl 是数据日期和发星日期的天数差】
2： dataset (输出表的属性需要和原来同名表的属性相同)
- EV_1KM_RefSB (存放算好的 arof 数据)
- EV_250_Aggr.1KM_RefSB (存放算好的 arof 数据)
- RSB_Cal_Cor_Coeff (存放新给的数据)
- SV_1KM_RefSB (存放从 OBC 文件提取的 SV 数据)
- SV_250_Aggr1KM_RefSB (存放从 OBC 文件提取的 SV 数据)








###############################################原文件###############################################

1、250m的前4个通道，先把sv 8000*24 使用 40 个探元转换为 200*24(选择 40 个探元中某个探元号的数据)，每个通道，可配置参数取某一个探元号
2、1000m的15个通道，先把sv 2000*6 使用 10 个探元 变为200*6(选择 10 个探元中某个探元号的数据)，每个通道，可配置参数取某一个探元号
3、然后按照10行滑动 从200*6 变成200*1
4、然后10行用1个sv均值，总的19*2000

全局属性k0,k1,k2 (判断是否要还原)  ，如果要还原(增加RSB_Cal_Cor_Coeff数据集了)  读取 slope 和 intercept
(1、dn*slope + intercep)
(2、RSB_Cal_Cor_Coeff的k0,k1,k2 (dsl**2 * k2 + dsl*k1 + k0)= slope(定标)
(3、1/slope+sv = DN)
(4、arof=(DN-sv200) *slope(dsl**2 * k2 + dsl*k1 + k0(我们给的(k2,k1,k0))) (*100输出)



DSL 写入属性

输出落地 arof = 按照原L1数据集名称命名(ev) 在*0.01之前
输出RSB_Cal_Cor_Coeff，我们给的k0,k1,k2 和之前不同
sv 是滑动后的200  变成2000 输出
共5个数据集

dsl = 天数差